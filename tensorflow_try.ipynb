{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow-macos in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (2.9.0)\n",
      "Collecting protobuf==3.20.3\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: wrapt==1.12.1 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (1.12.1)\n",
      "Collecting tensorflow-metal\n",
      "  Downloading tensorflow_metal-1.1.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (1.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (3.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (1.23.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (21.3)\n",
      "Requirement already satisfied: setuptools in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (63.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (4.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-macos) (2.9.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow-metal) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (2.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos) (3.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from packaging->tensorflow-macos) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-macos) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow-macos) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-macos) (3.2.2)\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metal-1.1.0-cp310-cp310-macosx_12_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -andas (/Users/michieldekoninck/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tensorflow-metal, protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.0\n",
      "    Uninstalling protobuf-3.20.0:\n",
      "      Successfully uninstalled protobuf-3.20.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contrastive-learning 0.1.0 requires aiohappyeyeballs==2.4.3, which is not installed.\n",
      "contrastive-learning 0.1.0 requires comm==0.2.2, which is not installed.\n",
      "contrastive-learning 0.1.0 requires contourpy==1.3.0, which is not installed.\n",
      "contrastive-learning 0.1.0 requires propcache==0.2.0, which is not installed.\n",
      "contrastive-learning 0.1.0 requires torchaudio==2.5.0, which is not installed.\n",
      "contrastive-learning 0.1.0 requires torchvision==0.20.0, which is not installed.\n",
      "contrastive-learning 0.1.0 requires absl-py==2.1.0, but you have absl-py 1.3.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires aiohttp==3.10.10, but you have aiohttp 3.8.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires aiosignal==1.3.1, but you have aiosignal 1.2.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires appnope==0.1.4, but you have appnope 0.1.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires asttokens==2.4.1, but you have asttokens 2.0.8 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires async-timeout==4.0.3, but you have async-timeout 4.0.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires attrs==24.2.0, but you have attrs 22.1.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires cycler==0.12.1, but you have cycler 0.11.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires debugpy==1.8.7, but you have debugpy 1.6.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires exceptiongroup==1.2.2, but you have exceptiongroup 1.2.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires executing==2.1.0, but you have executing 1.1.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires filelock==3.16.1, but you have filelock 3.12.4 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires fonttools==4.54.1, but you have fonttools 4.38.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires frozenlist==1.4.1, but you have frozenlist 1.3.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires fsspec==2024.9.0, but you have fsspec 2022.10.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires grpcio==1.67.0, but you have grpcio 1.62.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires idna==3.10, but you have idna 3.4 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires ipdb==0.13.13, but you have ipdb 0.13.9 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires ipykernel==6.29.5, but you have ipykernel 6.15.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires ipython==8.28.0, but you have ipython 8.5.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires jedi==0.19.1, but you have jedi 0.18.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires Jinja2==3.1.4, but you have jinja2 3.1.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires jupyter_client==8.6.3, but you have jupyter-client 7.4.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires jupyter_core==5.7.2, but you have jupyter-core 4.11.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires kiwisolver==1.4.7, but you have kiwisolver 1.4.4 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires lightning-utilities==0.11.8, but you have lightning-utilities 0.11.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires Markdown==3.7, but you have markdown 3.4.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires MarkupSafe==3.0.2, but you have markupsafe 2.1.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires matplotlib==3.9.2, but you have matplotlib 3.5.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires matplotlib-inline==0.1.7, but you have matplotlib-inline 0.1.6 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires multidict==6.1.0, but you have multidict 6.0.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires nest-asyncio==1.6.0, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires networkx==3.4.1, but you have networkx 2.8.7 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires numpy==1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires packaging==24.1, but you have packaging 21.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires pandas==2.2.3, but you have pandas 1.4.4 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires parso==0.8.4, but you have parso 0.8.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires pexpect==4.9.0, but you have pexpect 4.8.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires pillow==11.0.0, but you have pillow 9.1.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires platformdirs==4.3.6, but you have platformdirs 2.5.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires prompt_toolkit==3.0.48, but you have prompt-toolkit 3.0.31 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires protobuf==5.28.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires psutil==6.1.0, but you have psutil 5.9.3 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires pure_eval==0.2.3, but you have pure-eval 0.2.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires Pygments==2.18.0, but you have pygments 2.13.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires pyparsing==3.2.0, but you have pyparsing 3.0.9 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires python-dateutil==2.9.0.post0, but you have python-dateutil 2.8.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires pytorch-lightning==2.4.0, but you have pytorch-lightning 2.3.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires pytz==2024.2, but you have pytz 2022.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires PyYAML==6.0.2, but you have pyyaml 6.0.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires pyzmq==26.2.0, but you have pyzmq 24.0.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires seaborn==0.13.2, but you have seaborn 0.11.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires stack-data==0.6.3, but you have stack-data 0.5.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires sympy==1.13.1, but you have sympy 1.12 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires tensorboard==2.18.0, but you have tensorboard 2.9.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires tensorboard-data-server==0.7.2, but you have tensorboard-data-server 0.6.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires tomli==2.0.2, but you have tomli 2.0.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires torch==2.5.0, but you have torch 2.1.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires torchmetrics==1.5.0, but you have torchmetrics 1.4.0.post0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires tornado==6.4.1, but you have tornado 6.2 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires tqdm==4.66.5, but you have tqdm 4.64.1 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires traitlets==5.14.3, but you have traitlets 5.5.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires typing_extensions==4.12.2, but you have typing-extensions 4.4.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires tzdata==2024.2, but you have tzdata 2022.5 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires wcwidth==0.2.13, but you have wcwidth 0.2.5 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires Werkzeug==3.0.4, but you have werkzeug 3.0.0 which is incompatible.\n",
      "contrastive-learning 0.1.0 requires yarl==1.15.5, but you have yarl 1.8.1 which is incompatible.\n",
      "google-cloud-aiplatform 1.42.1 requires google-auth<3.0.0dev,>=2.14.1, but you have google-auth 2.13.0 which is incompatible.\n",
      "tensorflow 2.16.1 requires flatbuffers>=23.5.26, but you have flatbuffers 1.12 which is incompatible.\n",
      "tensorflow 2.16.1 requires h5py>=3.10.0, but you have h5py 3.7.0 which is incompatible.\n",
      "tensorflow 2.16.1 requires keras>=3.0.0, but you have keras 2.9.0 which is incompatible.\n",
      "tensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.23.4 which is incompatible.\n",
      "tensorflow 2.16.1 requires tensorboard<2.17,>=2.16, but you have tensorboard 2.9.0 which is incompatible.\n",
      "taxifare 0.0.5 requires numpy==1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
      "taxifare 0.0.5 requires pandas==1.5.3, but you have pandas 1.4.4 which is incompatible.\n",
      "taxifare 0.0.5 requires scikit-learn==1.2.1, but you have scikit-learn 1.3.1 which is incompatible.\n",
      "taxifare 0.0.5 requires tensorflow-macos==2.10.0, but you have tensorflow-macos 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3 tensorflow-metal-1.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-macos protobuf==3.20.3 wrapt==1.12.1 tensorflow-metal  # Optional for M1/M2 Macs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def data_augmentation(image):\n",
    "    image = tf.image.random_crop(image, size=[224, 224, 3])\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5)\n",
    "    image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Resize images to (224, 224, 3) and normalize to [0, 1] range\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.resize(image, [224, 224])  # Resize to match SimCLR input\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize\n",
    "    return image\n",
    "\n",
    "# Apply two distinct augmentations for SimCLR views\n",
    "def create_views(image):\n",
    "    augmented_view_1 = data_augmentation(preprocess_image(image))\n",
    "    augmented_view_2 = data_augmentation(preprocess_image(image))\n",
    "    return augmented_view_1, augmented_view_2\n",
    "\n",
    "# Prepare the dataset with two augmented views per image\n",
    "def prepare_dataset(x_data, batch_size=64):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(x_data)\n",
    "    dataset = dataset.map(create_views, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = prepare_dataset(x_train)\n",
    "test_dataset = prepare_dataset(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 1 batch shape: (64, 224, 224, 3)\n",
      "View 2 batch shape: (64, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 15:07:08.448463: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of one batch from the dataset\n",
    "for batch in train_dataset.take(1):\n",
    "    view_1, view_2 = batch\n",
    "    print(\"View 1 batch shape:\", view_1.shape)\n",
    "    print(\"View 2 batch shape:\", view_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_encoder():\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D()\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_projection_head(encoder_output_dim=2048, projection_dim=128):\n",
    "    return models.Sequential([\n",
    "        layers.Dense(encoder_output_dim, activation='relu'),\n",
    "        layers.Dense(projection_dim)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def nt_xent_loss(batch_size, temperature=0.5):\n",
    "    def loss_fn(z_i, z_j):\n",
    "        z = tf.concat([z_i, z_j], axis=0)\n",
    "        similarity_matrix = K.dot(z, K.transpose(z))\n",
    "        \n",
    "        # Create labels for positive pairs\n",
    "        mask = tf.one_hot(tf.range(batch_size), batch_size * 2)\n",
    "        mask = tf.concat([mask, mask], axis=0)\n",
    "        \n",
    "        # Exclude self-similarity\n",
    "        logits_mask = 1 - tf.eye(batch_size * 2)\n",
    "        mask *= logits_mask\n",
    "        \n",
    "        # Compute NT-Xent loss\n",
    "        logits = similarity_matrix / temperature\n",
    "        exp_logits = tf.exp(logits) * logits_mask\n",
    "        log_prob = logits - tf.math.log(tf.reduce_sum(exp_logits, axis=1, keepdims=True))\n",
    "        \n",
    "        mean_loss = -tf.reduce_sum(mask * log_prob) / (batch_size * 2)\n",
    "        return mean_loss\n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(tf.keras.Model):\n",
    "    def __init__(self, encoder, projection_head):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.projection_head = projection_head\n",
    "\n",
    "    def call(self, x):\n",
    "        h = self.encoder(x)                   # Encoder output\n",
    "        z = self.projection_head(h)            # Projected output for contrastive loss\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Step 0: Loss = nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m contrastive_loss_fn(z_i, z_j)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Apply gradients\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimclr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, simclr_model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1107\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1108\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1109\u001b[0m           output_gradients))\n\u001b[1;32m   1110\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1111\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1113\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    158\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/nn_grad.py:925\u001b[0m, in \u001b[0;36m_FusedBatchNormV3Grad\u001b[0;34m(op, *grad)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;129m@ops\u001b[39m\u001b[38;5;241m.\u001b[39mRegisterGradient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFusedBatchNormV3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_FusedBatchNormV3Grad\u001b[39m(op, \u001b[38;5;241m*\u001b[39mgrad):\n\u001b[0;32m--> 925\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_BaseFusedBatchNormGrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/nn_grad.py:905\u001b[0m, in \u001b[0;36m_BaseFusedBatchNormGrad\u001b[0;34m(op, version, *grad)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    904\u001b[0m   args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreserve_space_3\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m--> 905\u001b[0m dx, dscale, doffset, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCHW\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    907\u001b[0m   dx \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mtranspose(dx, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/gen_nn_ops.py:4223\u001b[0m, in \u001b[0;36mfused_batch_norm_grad_v3\u001b[0;34m(y_backprop, x, scale, reserve_space_1, reserve_space_2, reserve_space_3, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   4222\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4223\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4224\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFusedBatchNormGradV3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_backprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4225\u001b[0m \u001b[43m      \u001b[49m\u001b[43mreserve_space_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreserve_space_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreserve_space_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepsilon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4227\u001b[0m     _result \u001b[38;5;241m=\u001b[39m _FusedBatchNormGradV3Output\u001b[38;5;241m.\u001b[39m_make(_result)\n\u001b[1;32m   4228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the encoder and projection head\n",
    "encoder = create_encoder()\n",
    "projection_head = create_projection_head()\n",
    "\n",
    "# Create SimCLR model\n",
    "simclr_model = SimCLR(encoder, projection_head)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "contrastive_loss_fn = nt_xent_loss(batch_size=64, temperature=0.5)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for step, (view_1, view_2) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Pass both views through SimCLR model\n",
    "            z_i = simclr_model(view_1)\n",
    "            z_j = simclr_model(view_2)\n",
    "\n",
    "            # Calculate contrastive loss\n",
    "            loss = contrastive_loss_fn(z_i, z_j)\n",
    "        \n",
    "        # Apply gradients\n",
    "        gradients = tape.gradient(loss, simclr_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, simclr_model.trainable_variables))\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}: Loss = {loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
